# .env.example
# This file serves as a template for the .env file.
# Copy this file to .env and fill in the necessary values for local development.
# Do NOT commit the .env file to version control.

# -------------------------
# --- API Keys
# -------------------------

# Your API key for the Tavily search service.
# Required for the Search MCP Server to function.
TAVILY_API_KEY="your_key_here"

# Optional: If you want to use OpenAI as a fallback or primary LLM.
# OPENAI_API_KEY="sk-..."


# -------------------------
# --- LLM Configuration
# -------------------------

# The endpoint for the LLM. For local development, this might be a mock service.
# For a full OpenShift deployment, this would be the route to the kServe model.
GRANITE_ENDPOINT="http://127.0.0.1:8080"


# -------------------------
# --- RAG / Milvus Configuration
# -------------------------

# The host for the Milvus vector database service.
MILVUS_HOST="127.0.0.1"

# The port for the Milvus vector database service.
MILVUS_PORT="19530"

# The name of the sentence-transformer model to use for creating embeddings.
EMBEDDING_MODEL="all-MiniLM-L6-v2"


# -------------------------
# --- MCP Server Ports
# -------------------------
# Define the specific port for each MCP server to run on locally.

# Port for the LLM MCP Server.
LLM_MCP_PORT="8001"

# Port for the RAG MCP Server.
RAG_MCP_PORT="8002"

# Port for the Search MCP Server.
SEARCH_MCP_PORT="8003"

# Port for the Analytics MCP Server.
ANALYTICS_MCP_PORT="8004"


# -------------------------
# --- Debugging & Logging
# -------------------------

# Set the logging level. Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL="INFO"

# Set to "true" to enable verbose debugging output across the application.
MERIDIAN_DEBUG="false"

